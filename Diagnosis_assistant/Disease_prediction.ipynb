{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"def diagnosis_assistant():\n    st.title(\"Diagnostic Assistant ü©∫\")\n    \n    # Initialize chat history if not already present\n    if \"chat_history\" not in st.session_state:\n        st.session_state.chat_history = [{\"role\": \"assistant\", \"content\": INITIAL_RESPONSE}]\n    \n    # Display previous chat messages\n    for message in st.session_state.chat_history:\n        role = \"user\" if message[\"role\"] == \"user\" else \"assistant\"\n        avatar = \"üó®Ô∏è\" if role == \"user\" else \"üíâ\"\n        with st.chat_message(role, avatar=avatar):\n            st.markdown(message[\"content\"])\n    \n    # Get new input from the user\n    user_prompt = st.chat_input(\"Describe your symptoms here...\")\n    if user_prompt:\n        with st.chat_message(\"user\", avatar=\"üó®Ô∏è\"):\n            st.markdown(user_prompt)\n        st.session_state.chat_history.append({\"role\": \"user\", \"content\": user_prompt})\n        \n        # Create the conversation messages with context\n        messages = [\n            {\"role\": \"system\", \"content\": CHAT_CONTEXT},\n            {\"role\": \"assistant\", \"content\": INITIAL_RESPONSE}\n        ] + st.session_state.chat_history\n        \n        # Get response from the Groq API using the LLM\n        with st.chat_message(\"assistant\", avatar=\"üíâ\"):\n            stream = client.chat.completions.create(\n                model=\"llama3-8b-8192\",\n                messages=messages,\n                stream=True\n            )\n            response_content = \"\".join([chunk.choices[0].delta.content or \"\" for chunk in stream])\n            st.markdown(response_content)\n        \n        # Append the assistant's response to the chat history\n        st.session_state.chat_history.append({\"role\": \"assistant\", \"content\": response_content})\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null}]}